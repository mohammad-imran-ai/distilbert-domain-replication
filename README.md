# distilbert-domain-replication

*Reproduction of a transformer fine-tuning experiment (DistilBERT) on a domain-specific sentiment dataset, with full experiment configs, training scripts, evaluation notebooks, and logging to enable exact replication and comparison to the original paper. Includes hyperparameters, seeds, result tables, and notes on discrepancies.*

*Problem: reproduce fine-tuning results of DistilBERT on a niche sentiment dataset. Deliverables: training and eval scripts, experiment configs (YAML), notebooks with plots/tables, model checkpoints, and reproducibility instructions.*

Quick start: clone → setup env → python train.py --config configs/exp1.yaml.


